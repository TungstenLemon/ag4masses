
# AG4Masses: AlphaGeometry for the Masses


An exciting recent development in AI with rigorous logical reasoning ability is the [AlphaGeometry](https://www.nature.com/articles/s41586-023-06747-5) system developed by Google Deepmind. Google made the source code for running AlphaGeometry available on GitHub at [google-deepmind/alphageometry](https://github.com/google-deepmind/alphageometry). However, the AlphaGeometry system as Google released, with the Language Model trained by Google, still requires a tremendous amount of computing power to run when solving problems. As Google's paper mentioned, in order to solve IMO level problems in about 1.5 hour, it needed 4 GPU V100 and up to 250 CPUs. These are not the kind of hardware casual users and hobbists have access to.

AlphaGeometry includes a powerful deductive engine DD+AR that can solve virtually all the plane geomety problems that do not require auxilary points within a few minutes with household hardwares. The ultimate performance of the system hinges on the ability to add auxilary points that lead to the solution. In AlphaGeometry, this is done by the Language Model. My tests shown that, for many classic problems, AlphaGeometry failed to solve them after trying more than ~8000 figures with added auxilary points. For humans, the number of figures attemped is typically under 100. This indicates that there is still vast room to improve the performance of AlphaGeometry.

Since the initial open-sourcing in January 2024, as of April 2024, there has been no update to the AlphaGeometry repository. It is unclear whether Google plans to continue developing AlphaGeometry. The AG4Masses project is a fork of [google-deepmind/alphageometry](https://github.com/google-deepmind/alphageometry). I hope to build on the wonderful foundation AlphaGeometry has laid, continue to improve it, bring its powers to everyday users and hobbists, and provide useful insights to future developments of AI with rigorous logical reasoning ability.

# The Goal of AG4Masses

The goal of this project is to **improve the performance of AlphaGeometry by a factor of ~100** to enable it to **solve IMO level (hence vast majority of) plane geometry problems with household hardwares (as of 2024, 4-8 logical CPU, 16-32G RAM, no high-end GPU) within a day**.

# What's Provided in AG4Masses (as of April 2024)

## Code Improvements over AlphaGeometry
* Added the ability to use multiple CPUs on a symmetric multiprocessor machine to improve speed
* Fixed some bugs
* Improved robustness by handling many error conditions that would have caused AlphaGeometry to abort
* Improved logging
* Utility scripts for running AG4Masses, analysing run-time log, monitoring progress of a run, etc.

## Test Results
The the [XXX logs] directory contains log files of many test cases. The 'solved' subfolder are problems solved, most of the problems also come with an image file showing the diagram of the problem. Most of the diagrams are generated by AlphaGeometry automatically, sometimes such diagrams are not very easy to read. For some problems I manually created more readable images, file names of the mannually generated diagrams are tagged with '-manual'. The 'unsolved" subfolder are problems that I have not been able to solve with hardwares available to me, after attemping 7500-9500 figures. The auxilary points added by AlphaGeometry can be found by searching lines like:

`I0304 22:44:12.423360 140094168801280 alphageometry.py:548] Worker 0: Translation: "i = on_line i b c, on_bline i c b"`

The test problems are in the [XXX problems_ag4m.txt] file. Note that there are some small differences in the format of the log files for different problems because of code changes over time.

The naming convention of the log files is: for problems that can be solved by ddar (no auxilary point needed), the file name contains 'ddar-ok'; for problems that need AlphaGeometry (need auxilary points), the file name contains 'ag-ok'.

Below are a few examples:

### The 5-Circles Problem (logs/solved/5circles-ddar-ok.log):

A, B, C, D, E are vertices of a pentagon. F, G, H, I, J are intersections of their diagonals. 5 circumcircles of triangles AJF, BFG etc. intersect at 5 points P, Q, R, S, T, in addition to F, G, H, I, J. Prove that F, G, H, I, J are concyclic.

<center>
<img alt="5circles-manual" width="800px" src="../agtest/logs/solved/5circles-manual.jpg">
</center>

It turns out no auxilary point is needed for this problem, it can be solved by DD+AR, taking 6 minutes with 1 CPU in use. This problem is not easy for humans given there are many points on the diagram and it's not easy to see all the relatioships between them. This shows the power of the DD+AR engine.

### The 15-Degree-Line-in-Square Problem (logs/solved/square_angle15-ag-ok.log):

A, B, C, D is a square. E is inside the square and CDE = ECD = 15-degree. Prove that ABE is an equilateral triangle.

<center>
<img alt="square_angle15.jpg" width="800px" src="../agtest/logs/solved/square_angle15.jpg">
</center>

This needs an auxilary point and AlphaGeometry found it very quickly (13 minutes, about 1 CPU in use, no GPU), on the 3rd try (and the first valid diagram).

I remember I first encountered this problem in the middle school, a few months after learning geometry. An obvious solution was an indirect one: construct an equilateral triangle ABE with AB as one side and E inside the square, show that CDE = ECD = 15-degree, then argue that there is only one point that can satisfy this condition. But I and several other classmates were not satisfied with the indirect solution and wanted to find a direct one. 5-6 of us spend 1-2 hours before one student solved it. In that exercise, it took about 10 hours of intense execution by enthusiatic and lightly trained young human brains. Even on very basic hardwares, AlphaGeometry is already better than a novice human problem solver.

### The Napoleon Problem (logs/solved/napoleon-ddar-ok.log, logs/solved/napoleon2-mp-4-solutions-ag-ok.log)

For any triangle ABC, construct equilateral triangles with one of the sides as a side (the 3 equilaterals must be in the same direction relative to ABC, either all "going out" or all "going in"). The centers of the 3 equilateral triangles - D, E, F - form an equilateral triangle.

If the problem is stated this way, no additional auxilary point is needed, it can be solved by DD+AR, see napoleon-ddar-ok.log.

<center>
<img alt="napoleon.jpg" width="800px" src="../agtest/logs/solved/napoleon.jpg">
</center>

A more challenging version is to give points D, E, F through the conditions that angles DAB, ABD, EBC, BCE, etc. all equal 30-degree. This will need auxilary points. In my run AlphaGeometry found 4 solutions, they require 4 auxilary points. AlphaGeometry found the first after trying around 360 figures. See napoleon2-mp-4-solutions-ag-ok.log.

<center>
<img alt="napoleon2-mp-2.jpg" width="800px" src="../agtest/logs/solved/napoleon2-mp-2.jpg">
</center>

### Ceva's Theorem (logs/unsolved/ceva-mp-16-crash.log)

For any triangle ABC and point D, points E is the interception of AD and BC, and so on for F, G. Prove that AG/GB * BE/EC * CF/FA = 1 (a more general way to state the theorem considers sign of the segments and rhs is -1). Here we run into a limitation of AlphaGeometry: it does not support complex conclusions (goals to be proved) like the one in the Ceva's Theorem, only equality of two ratios. To work around this, I added an auxilary point H on AC with BH // EF, and transformed the conclusion to FH/FA = GB/GA.

<center>
<img alt="ceva-manual.jpg" width="800px" src="../agtest/logs/solved/ceva-manual.jpg">
</center>

In my test this problem was not solved by AlphaGeometry after over 10k figures, see ceva-mp-16-crash.log. The machine I used eventually ran out of memory as the figures got more complex. It's intersting to look at the auxilary points AlphaGeometry attempted to add. To a human, observing that the problem is very general, there are very few relationships given, and the conclusion is about ratio of segments, it will be very natural to try to add parallel lines to constuct similar triangles. Indeed a typical solution only requires two auxilary points, e.g. draw a line over A parallel to BC, extend CD and BD to meet this line. But only about 10% of AlphaGeometry's auxilary points for this problem involve parallel lines. For this and other problems I tried, I find AlphaGeometry to prefer adding midpoints and mirror points around another point or a line. AlphaGeometry also seems to perform worse for problems like this one whose premises are simple with few relationships given.

# Plan for Future Developments

## Improve the Language Model that Adds Auxilary Points

The DD+AR deduction engine can solve virtually any problem in a few minutes with household hardware. The performance of the system all hinges on the LM's ability to add auxilary points effectively. As Google's paper mentions, the current model is trained on 100 million randomly generated problems, with nearly 10 million involving auxilary points. Yet as we observed in the [Test Results](#test-results) section above, the performance still has vast room to improve. Humans typically cannot try more than ~100 figures, but top human problem solvers perform better than what the current version of AlphaGeometry can do with thousands of times more attempts.

I believe this requires tuning the LM using data based on **human designed** problems. Although many strategic search type of problems have been solved very successfully by approaches from first principles without requiring human inputs, such as Google Deepmind's AlphaZero for many challenging board and video games, math and scientific research in general and plane geometry in particular are different. Unlike the board and video games that have simple and clearly defined goals, other than a few areas such as proof of Riemann's Hypothesis, math and science research have no such simple and clearly defined final goals. The active research areas are defined by collective activites and interests of researchers in the fields. Even major breakthroughs such as calculus, theory of relativity and quantum mechanics were still pretty close to the frontier of human knowledge at their times. Looking at plane geometry in particular, it is not an active area of continued mathematical discovery any more, the interest in it is main for education, recreation and as test cases for AI research. So the performane of a problem solving system is measured by its ability to solve human designed problems. A system like the current version of AlphaGeometry trained on randomly generated problems may be strong in solving random problems, but not particularly strong in solving the kind of problems commonly of interest to humans, which are mostly **designed by humans**(instead of arising naturally in some way).

As Google's paper mentions, the challenge in training a model to solve plane geometry problem is the scarcity of data, that's one reason the authers used randomly generated problems. However, with the advent of the AlphaGeometry system, we can use AlphaGeometry itself as a platform to collect data. There are already some quite large plane geometry problem sets available in electronic form, such as [FormalGeo7k](https://github.com/FormalGeo/Datasets/tree/main/projects/formalgeo7k) with 7k problems. What's missing is for problems that require auxilary points, knowing the auxilary points that lead to the solution of the problem. This can be obtained either manually (if one knows the solution) or by successful solution by the latest version of AlphaGeometry or one of its improved versions such as AG4Masses. To estimate the number of data points needed, we again use human as reference. A top human problem solver is probably trained on less than 1k problems. If we can collect 10k problems with auxilary points, I believe they can significantly improve the performance of the LM. The specific tasks include:

* Define a format to record problems and auxilary points, enhance the AG4Masses code so when a problem is successfully solved, record the problem and auxilary points in the standard format. Automatically submit the results to the AG4Masses project, with the user's consent. [Effort Level: low]
* Investigate ways to tune the LM. Google has not published the code and details for the training and tuning of the LM. The [Meliad](https://github.com/google-research/meliad) project AlphaGeometry uses does not have much documentation (other than several related published papers), so this may be challenging. [Effort Level: high]
* Tune the model once a meaningful amount of data are collected. I am not sure about the amount of computing power needed for this, need further investigation. [Effort Level: potentially high]

## Improve Problem Solving Stragety and Algorithm

When searching for auxilary points, the current version of AlphaGeometry simply does a beam (breadth-first with pruning) search from the premises of the problem. A strategy commonly used by humans is to also look from the conclusion backwards: find sufficient conditions of the conclusion, and attempt to prove one of the sufficient conditions. Intuitively, this enlarges the goal we are searching for.

One way to look for sufficient conditions is to look for necessary conditions of the conclusion, i.e. what can be deduced from the problem's premises **and the conclusion**, then test whether the necessary conditions are also sufficient. This is especially effective for human designed problems because the authors of the problems usually have already made the problems as general as possible, i.e. there is usually no sufficient but not necessary conditions provable from the premises. The specific tasks are, at each step of the auxilary point searching process:

* Add the conclusion of the problem into the premises (including the auxilary points already added), use the DD+AR engine to find all necessary conditions (what can be deduced), and use DD+AR to verify whether each of them is a sufficient condition
* For each sufficient condition found, when running the LM to search for the next auxilary point, change the conclusion to the sufficient condition

This should hopefully improve the effectiveness of the auxilarry points, but it needs to be balanced with the runtime cost incurred.

There may be other ways to improve the problem solving strategy, such as combining hand-crafted heuristics with the LM model.

Effort Level: high, but more certain since it does not require changes to the LM itself

## Enhance the Range of Geometry Problems Handled by the System

AlphaGeometry's problem definition language is restrictive, for example:

* Premise specification does not allow construction of points based on ratio of segment lenths
* The conclusion specification does not allow complex conditional involving arithmatics, such as sum of length of 2 segments equaling length of another segment, or product of 3 segment length ratios, like in Ceva's Theorem

These limited the scope of problems that can be handled by the system. At least for the two examples mentioned above, it should not be too difficult to add them into the DD+AR part of the system, but the LM's performance for problems involving these new constucts may be degraded, since the LM model's training dataset does not contain such constructs. To maintain the performance of the LM model, we may need to wait for Google to publish the code and data set for LM model training. Even with the code and data, the computing power needed for retaining the model may be beyond the reach of the an online community. Another possibility is to develop a way to transform such constructs to the ones AlphaGeometry handles.

Effort Level: medium for extending DD+AR, high for ensuring performance of the LM for the new constructs

## Improve the User Friendliness and Robustness of the System

The AlphaGeometry system is not very user friendly, and not very robust. For example:

* The problem definition language syntax is very strict, it's sensitive to white spaces
* The code does not do a very good job checking correctness of problem definition. When a problem definition has errors or the proposation is false, the code often just freezes. When it catches a error, the error message is often hard to understand
* The LM does not always return valid auxilary point construction. The code captures most of these, but there are still some uncaught ones that will cause the execution to abort

 I already made some improvements in AG4Masses in these aspects, but more can be done.

 Effort Level: low to medium

# Some Tips and Experiences about the AlphaGeometry System

Below are based on my testing and reading of the source code.

## The Problem Definition Language

Below is a problem from examples.txt:

```
orthocenter
a b c = triangle; h = on_tline b a c, on_tline c a b ? perp a h b c
```

* A problem consists of 2 lines, the first line is the name of the problem, the second line is the definition
* The problem definition is **sensitive to white spaces, including trailing ones**
* The problem definition consists of premises and a conclusion, separated by `' ? '`
* The premises consist of multiple clauses for constructing points, the best way is to think of the process of drawing the points one by one
* Multiple point-construction clauses are separated by `' ; '`. Note that the last one should **not** end with `' ; '`, before the `' ? '` separating the premises and the conclusion
* Some point-construction clauses can construct multiple points, such as `'a b c = triangle'`
* A point-construction clause consists of point names (separated by a single space), followed by `' = '`, and 1 or 2 "actions" (the term used in the Google paper), separated by `' , '`. See in the above examle: `h = on_tline b a c, on_tline c a b`
* Actions are defined in the defs.txt file. They are also listed in the Google paper in "Extended Data Table 1 | List of actions to construct the random premises". Each action is a constraint on the position of the point. Construction a point using actions is similar to construction it using straight edge and compass, e.g. find the point through intersection of 2 lines
* An action is similar to a function call, with other points being inputs and the point to be constructed being output
* Output point names can be optionally repeated in the beginning of the inputs (arguments) of the actions. For example, `h = on_tline b a c, on_tline c a b` can also be `h = on_tline h b a c, on_tline h c a b`. In defs.txt the output point names are repeated in front of the input point names. This sometimes makes the action more clear to read
* It's possible to add actions but it's not enough to just add into the defs.txt file. In defs.txt, each action is defined by 5 lines. The last line invovles functions needed for numerical checking that need to be implemented in Python
* The conclusion (goal) part of the problem can have one of the following statements:
  * `coll a b c` : points a b c are collinear
  * `cong a b c e` : segments ab and cd are congruent (length equal)
  * `contri a b c p q r` : triangles abc and pqr are congruent
  * `cyclic a b c d` : 4 points a b c d are cocyclic
  * `eqangle a b c d p q r s` : angle between lines ab-cd and pq-rs are equal. **Note that angles have directions (signs)** so the order between `a b` and `c d` matters. `eqangle a b c d c d a b` is false. The way to think about it is, angle ab-cd is the angle to turn line ab **clockwise** so it is parallel with the line cd. You can use counter-clockwise as the convention too, as long as for all angles the same convention is used
  * `eqratio a b c d p q r s` : segment length ab/cd = pq/rs
  * `midp m a b` : point m is the midpoint of a and b
  * `para a b c d` : segments ab and cd are parallel
  * `perp a b c d` : segments ab and cd are perpendicular to each other
  * `simtri a b c p q r` : triangles abc and pqr are similar

## Some Tips

* **Angles have directions (signs)**. See the note for `eqangle` above. Attention needs to be paid both in the premise (point construction) part and the conclusion part of the problem

* AlphaGeometry does not do robust error checking of the problem or the proposation. If the problem has syntax errors or the proposation is false, it often freezes. To detect this, look at the log on stderr. AlphaGeometry will first try to solve the problem using DD+AR, and on stderr, you should see logs like this:

```
I0324 19:53:37.293019 123295230480384 graph.py:498] pascal
I0324 19:53:37.293379 123295230480384 graph.py:499] a = free a; b = free b; c = on_circle c a b; d = on_circle d a b; e = on_circle e a b; f = on_circle f a b; g = on_circle g a b; h = intersection_ll h b c e f; i = intersection_ll i c d f g; j = intersection_ll j d e g b ? coll h i j
I0324 19:53:38.638956 123295230480384 ddar.py:60] Depth 1/1000 time = 1.2907805442810059
I0324 19:53:42.962377 123295230480384 ddar.py:60] Depth 2/1000 time = 4.3230626583099365
I0324 19:53:47.302527 123295230480384 ddar.py:60] Depth 3/1000 time = 4.3398051261901855
```

Using the the AG4Masses code, this should happen right away. Using the original AlphaGeometry code, when the model is `alphageometry`, it will take several minutes to get there because the original AlphaGeometry code loads the LM first. In any case, if you do not see this after several minutes, chances are there is an error in the syntax of the problem or the proposation is false.

One trick to error check a problem's syntax and generate the diagram for the problem is to first use a trivial conclusion such as `cong a b a b`. If the rest of the problem is correct, it will be proven right away, and you will get a diagram generated by the code. 

## Dependencies

For the instructions presented below,
we use Python 3.10.9, and dependencies with their exact
version numbers listed in `requirements.txt`.

Our code depends on `meliad`, which is
not a registered package with `pip`. See instructions below
for how to manually install `meliad`.

Note that one can still run the DDAR solver
without the `meliad` and `sentencepiece` dependencies.

## Run the instructions

All instructions in this `README.md` can be run in one go by:

```
bash run.sh
```

Below, we explain these instructions step-by-step.

## Install dependencies, download weights and vocabulary.

Installation is done in a virtual environment:

```
virtualenv -p python3 .
source ./bin/activate
pip install --require-hashes -r requirements.txt
```

Download weights and vocabulary:

```
bash download.sh
DATA=ag_ckpt_vocab
```

Finally, install `meliad` separately as it is not
registered with `pip`:

```
MELIAD_PATH=meliad_lib/meliad
mkdir -p $MELIAD_PATH
git clone https://github.com/google-research/meliad $MELIAD_PATH
export PYTHONPATH=$PYTHONPATH:$MELIAD_PATH
```

## Set up common flags

Before running the python scripts,
let us first prepare some commonly used flags.
The symbolic engine needs definitions and deduction rules to operate.
These definitions and rules are provided in two text files
`defs.txt` and `rules.txt`.

```shell
DDAR_ARGS=(
  --defs_file=$(pwd)/defs.txt \
  --rules_file=$(pwd)/rules.txt \
);
```

Next, we define the flags relevant to the proof search.
To reproduce the simple examples below,
we use lightweight values for the proof search parameters:

```shell
BATCH_SIZE=2
BEAM_SIZE=2
DEPTH=2

SEARCH_ARGS=(
  --beam_size=$BEAM_SIZE
  --search_depth=$DEPTH
)
```

NOTE: The results in our paper can be obtained by setting
`BATCH_SIZE=32`, `BEAM_SIZE=512`, `DEPTH=16`
as described in section Methods.
To stay under IMO time limits, 4 V100-GPUs and 250 CPU workers
are needed as shown in Extended Data - Figure 1.
Note that we also strip away other memory/speed optimizations
due to internal dependencies and to promote code clarity.

Assume the downloaded checkpoint and vocabulary is placed in `DATA`,
and the installed `meliad` source code is at `MELIAD_PATH`.
We make use of the `gin` library to manage model configurations,
following `meliad` conventions. We now define the flags relevant to the
language model:

```shell
LM_ARGS=(
  --ckpt_path=$DATA \
  --vocab_path=$DATA/geometry.757.model
  --gin_search_paths=$MELIAD_PATH/transformer/configs,$(pwd) \
  --gin_file=base_htrans.gin \
  --gin_file=size/medium_150M.gin \
  --gin_file=options/positions_t5.gin \
  --gin_file=options/lr_cosine_decay.gin \
  --gin_file=options/seq_1024_nocache.gin \
  --gin_file=geometry_150M_generate.gin \
  --gin_param=DecoderOnlyLanguageModelGenerate.output_token_losses=True \
  --gin_param=TransformerTaskConfig.batch_size=$BATCH_SIZE \
  --gin_param=TransformerTaskConfig.sequence_length=128 \
  --gin_param=Trainer.restore_state_variables=False
);
```

TIP: Note that you can still run the DDAR solver
without defining `SEARCH_ARGS` and `LM_ARGS`.
In such case, simply disable the import of the `lm_inference` module
inside `alphageometry.py`.

## Run DDAR

The script loads a problem by reading a list of problems
from a text file and solves the specific problem in the list according
to its name. We pass these two pieces of information through the flags
`--problems_file` and `--problem_name`.
We use `--mode=ddar` to indicate that we want to use the DDAR solver.

Below we showed this solver solving IMO 2000 P1:

```shell
python -m alphageometry \
--alsologtostderr \
--problems_file=$(pwd)/imo_ag_30.txt \
--problem_name=translated_imo_2000_p1 \
--mode=ddar \
"${DDAR_ARGS[@]}"
```

Expect the following output

```shell
graph.py:468] translated_imo_2000_p1
graph.py:469] a b = segment a b; g1 = on_tline g1 a a b; g2 = on_tline g2 b b a; m = on_circle m g1 a, on_circle m g2 b; n = on_circle n g1 a, on_circle n g2 b; c = on_pline c m a b, on_circle c g1 a; d = on_pline d m a b, on_circle d g2 b; e = on_line e a c, on_line e b d; p = on_line p a n, on_line p c d; q = on_line q b n, on_line q c d ? cong e p e q
ddar.py:41] Depth 1/1000 time = 1.7772269248962402
ddar.py:41] Depth 2/1000 time = 5.63526177406311
ddar.py:41] Depth 3/1000 time = 6.883412837982178
ddar.py:41] Depth 4/1000 time = 10.275688409805298
ddar.py:41] Depth 5/1000 time = 12.048273086547852
alphageometry.py:190]
==========================
 * From theorem premises:
A B G1 G2 M N C D E P Q : Points
AG_1 ⟂ AB [00]
BA ⟂ G_2B [01]
G_2M = G_2B [02]
G_1M = G_1A [03]

...
[log omitted]
...

036. ∠QEB = ∠(QP-EA) [46] & ∠(BE-QP) = ∠AEP [55] ⇒  ∠EQP = ∠QPE [56]
037. ∠PQE = ∠EPQ [56] ⇒  EP = EQ

==========================
```

The output first includes a list of relevant premises that it uses,
and then proof steps that gradually build up the proof.
All predicates are numbered to track how they are derived
from the premises, and to show that the proof is fully justified.

TIP: Additionally passing the flag `--out_file=path/to/output/text/file.txt`
will write the proof to a text file.

Running on all problems in `imo_ag_30.txt` will yield solutions to
14 of them, as reported in Table 1 in our paper.

## Run AlphaGeometry:

As a simple example, we load `--problem_name=orthocenter`
from `--problem_file=examples.txt`.
This time, we pass `--mode=alphageometry` to use the AlphaGeometry solver
and pass the `SEARCH_ARGS` and `LM_ARGS` flags.

```shell
python -m alphageometry \
--alsologtostderr \
--problems_file=$(pwd)/examples.txt \
--problem_name=orthocenter \
--mode=alphageometry \
"${DDAR_ARGS[@]}" \
"${SEARCH_ARGS[@]}" \
"${LM_ARGS[@]}"
```

Expect the following output:

```shell
...
[log omitted]
...
training_loop.py:725] Total parameters: 152072288
training_loop.py:739] Total state size: 0
training_loop.py:492] Training loop: creating task for mode beam_search

graph.py:468] orthocenter
graph.py:469] a b c = triangle a b c; d = on_tline d b a c, on_tline d c a b ? perp a d b c
ddar.py:41] Depth 1/1000 time = 0.009987592697143555 branch = 4
ddar.py:41] Depth 2/1000 time = 0.00672602653503418 branch = 0
alphageometry.py:221] DD+AR failed to solve the problem.
alphageometry.py:457] Depth 0. There are 1 nodes to expand:
alphageometry.py:460] {S} a : ; b : ; c : ; d : T a b c d 00 T a c b d 01 ? T a d b c {F1} x00
alphageometry.py:465] Decoding from {S} a : ; b : ; c : ; d : T a b c d 00 T a c b d 01 ? T a d b c {F1} x00
...
[log omitted]
...
alphageometry.py:470] LM output (score=-1.102287): "e : C a c e 02 C b d e 03 ;"
alphageometry.py:471] Translation: "e = on_line e a c, on_line e b d"

alphageometry.py:480] Solving: "a b c = triangle a b c; d = on_tline d b a c, on_tline d c a b; e = on_line e a c, on_line e b d ? perp a d b c"
graph.py:468]
graph.py:469] a b c = triangle a b c; d = on_tline d b a c, on_tline d c a b; e = on_line e a c, on_line e b d ? perp a d b c
ddar.py:41] Depth 1/1000 time = 0.021120786666870117
ddar.py:41] Depth 2/1000 time = 0.033370018005371094
ddar.py:41] Depth 3/1000 time = 0.04297471046447754
alphageometry.py:140]
==========================
 * From theorem premises:
A B C D : Points
BD ⟂ AC [00]
CD ⟂ AB [01]

 * Auxiliary Constructions:
E : Points
E,B,D are collinear [02]
E,C,A are collinear [03]

 * Proof steps:
001. E,B,D are collinear [02] & E,C,A are collinear [03] & BD ⟂ AC [00] ⇒  ∠BEA = ∠CED [04]
002. E,B,D are collinear [02] & E,C,A are collinear [03] & BD ⟂ AC [00] ⇒  ∠BEC = ∠AED [05]
003. A,E,C are collinear [03] & E,B,D are collinear [02] & AC ⟂ BD [00] ⇒  EC ⟂ EB [06]
004. EC ⟂ EB [06] & CD ⟂ AB [01] ⇒  ∠(EC-BA) = ∠(EB-CD) [07]
005. E,C,A are collinear [03] & E,B,D are collinear [02] & ∠(EC-BA) = ∠(EB-CD) [07] ⇒  ∠BAE = ∠CDE [08]
006. ∠BEA = ∠CED [04] & ∠BAE = ∠CDE [08] (Similar Triangles)⇒  EB:EC = EA:ED [09]
007. EB:EC = EA:ED [09] & ∠BEC = ∠AED [05] (Similar Triangles)⇒  ∠BCE = ∠ADE [10]
008. EB:EC = EA:ED [09] & ∠BEC = ∠AED [05] (Similar Triangles)⇒  ∠EBC = ∠EAD [11]
009. ∠BCE = ∠ADE [10] & E,C,A are collinear [03] & E,B,D are collinear [02] & ∠EBC = ∠EAD [11] ⇒  AD ⟂ BC
==========================

alphageometry.py:505] Solved.
```

NOTE: Point `H` is automatically renamed to `D`,
as the LM is trained on synthetic problems
where the points are named alphabetically, and so it expects
the same during test time.

NOTE: In this implementation of AlphaGeometry,
we removed all optimizations that are dependent on
internal infrastructure, e.g.,
parallelized model inference on multi GPUs,
parallelized DDAR on multiple CPUs,
parallel execution of LM and DDAR,
shared pool of CPU workers across different problems, etc.
We also removed some memory/speed optimizations and code
abstractions in favor of code clarity.

As can be seen in the output, initially DDAR failed to solve the problem.
The LM proposes two auxiliary constructions (because `BATCH_SIZE=2`):

* `e = eqdistance e c a b, eqdistance e b a c`, i.e.,
construct `E` as the intersection of circle (center=C, radius=AB) and
circle (center=B, radius=AC). This construction has a score of `-1.186`.
* `e = on_line e a c, on_line e b d`, i.e.,
`E` is the intersection of `AC` and `BD`.
This construction has a higher score (`-1.102287`) than the previous.

Since the second construction has a higher score, DDAR attempted the second
construction first and found the solution right away.
The proof search therefore terminates and there is no second iteration.

## Results

Before attempting to reproduce the AlphaGeometry numbers in our paper,
please make sure to pass all tests in the prepared test suite:

```
bash run_tests.sh
```

NOTE: [Issues#14](https://github.com/google-deepmind/alphageometry/issues/14) reports that although the top beam decodes are still the same, the LM is not giving the same score for different users.

Then, pass the corresponding values for `--problem_file` (column)
and `--mode` (row), and
iterate on all problems to obtain the following results:

<center>

<b>Number of solved problems:</b>

|          | `imo_ag_30.txt`  | `jgex_ag_231.txt` |
|----------|------------------|-------------------|
| `ddar`   | 14               | 198               |
| `alphageometry`     | 25               | 228               |

</center>

## Source code description

Files in this repository include python modules/scripts to run the solvers and
resource files necessary for the script to execute. We listed below
each of them and their description.

| File name              | Description                                                                        |
|------------------------|------------------------------------------------------------------------------------|
| `geometry.py`          | Implements nodes (Point, Line, Circle, etc) in the proof state graph.              |
| `numericals.py`        | Implements the numerical engine in the dynamic geometry environment.               |
| `graph_utils.py`       | Implements utilities for the proof state graph.                                    |
| `graph.py`             | Implements the proof state graph.                                                  |
| `problem.py`           | Implements the classes that represent the problem premises, conclusion, DAG nodes. |
| `dd.py`                | Implements DD and its traceback.                                                   |
| `ar.py`                | Implements AR and its traceback.                                                   |
| `trace_back.py`        | Implements the recursive traceback and dependency difference algorithm.            |
| `ddar.py`              | Implements the combination DD+AR.                                                  |
| `beam_search.py`       | Implements beam decoding of a language model in JAX.                               |
| `models.py`            | Implements the transformer model.                                                  |
| `transformer_layer.py` | Implements the transformer layer.                                                  |
| `decoder_stack.py`     | Implements the transformer decoder stack.                                          |
| `lm_inference.py`      | Implements an interface to a trained LM to perform decoding.                       |
| `alphageometry.py`                | Main script that loads problems, calls DD+AR or AlphaGeometry solver, and prints solutions.   |
| `pretty.py`            | Pretty formating the solutions output by solvers.                                  |
| `*_test.py`            | Tests for the corresponding module.                                                |
| `download.sh`          | Script to download model checkpoints and LM                                        |
| `run.sh`               | Script to execute instructions in README.                                          |
| `run_tests.sh`         | Script to execute the test suite.                                                  |


Resource files:

| Resource file name     | Description                                                                        |
|------------------------|------------------------------------------------------------------------------------|
| `defs.txt`             | Definitions of different geometric construction actions.                           |
| `rules.txt`            | Deduction rules for DD.                                                            |
| `geometry_150M_generate.gin`| Gin config of the LM implemented in meliad.                                   |
| `imo_ag_30.txt`        | Problems in IMO-AG-30.                                                             |
| `jgex_ag_231.txt`      | Problems in JGEX-AG-231.                                                           |



## Citing this work

```bibtex
@Article{AlphaGeometryTrinh2024,
  author  = {Trinh, Trieu and Wu, Yuhuai and Le, Quoc and He, He and Luong, Thang},
  journal = {Nature},
  title   = {Solving Olympiad Geometry without Human Demonstrations},
  year    = {2024},
  doi     = {10.1038/s41586-023-06747-5}
}
```

## Acknowledgements

This research is a collaboration between the Google Brain team
(now Google Deepmind) and
the Computer Science Department of New York University.
We thank Rif A. Saurous, Denny Zhou, Christian Szegedy, Delesley Hutchins,
Thomas Kipf, Hieu Pham, Petar Veličković, Debidatta Dwibedi,
Kyunghyun Cho, Lerrel Pinto, Alfredo Canziani,
Thomas Wies, He He’s research group,
Evan Chen (the USA’s IMO team coach),
Mirek Olsak, Patrik Bak,
and all three Nature's referees for their help and support.

The code of AlphaGeometry communicates with and/or references the following
separate libraries and packages:

*   [Abseil](https://github.com/abseil/abseil-py)
*   [JAX](https://github.com/google/jax/)
*   [matplotlib](https://matplotlib.org/)
*   [NumPy](https://numpy.org)
*   [SciPy](https://scipy.org)
*   [TensorFlow](https://github.com/tensorflow/tensorflow)
*   [Meliad](https://github.com/google-research/meliad)
*   [Flax](https://github.com/google/flax)
*   [Gin](https://github.com/google/gin-config)
*   [T5](https://github.com/google-research/text-to-text-transfer-transformer)
*   [SentencePiece](https://github.com/google/sentencepiece)



We thank all their contributors and maintainers!


## Disclaimer

This is not an officially supported Google product.

This research code is provided "as-is" to the broader research community.
Google does not promise to maintain or otherwise support this code in any way.

## Code License

Copyright 2023 DeepMind Technologies Limited

All software is licensed under the Apache License, Version 2.0 (Apache 2.0);
you may not use this file except in compliance with the Apache 2.0 license.
You may obtain a copy of the Apache 2.0 license at:
https://www.apache.org/licenses/LICENSE-2.0

All other materials are licensed under the Creative Commons Attribution 4.0
International License (CC-BY). You may obtain a copy of the CC-BY license at:
https://creativecommons.org/licenses/by/4.0/legalcode

Unless required by applicable law or agreed to in writing, all software and
materials distributed here under the Apache 2.0 or CC-BY licenses are
distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
either express or implied. See the licenses for the specific language governing
permissions and limitations under those licenses.

## Model Parameters License

The AlphaGeometry checkpoints and vocabulary are made available
under the terms of the Creative Commons Attribution 4.0
International (CC BY 4.0) license.
You can find details at:
https://creativecommons.org/licenses/by/4.0/legalcode

